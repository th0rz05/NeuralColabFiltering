{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10944744,"sourceType":"datasetVersion","datasetId":6807254}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Slot Game Recommendation System with PyTorch & BPR Loss\n\nThis notebook presents a production-ready implementation of a recommendation system for our online casino. We build a Neural Collaborative Filtering (NCF) model in PyTorch that is trained using Bayesian Personalized Ranking (BPR) loss. This approach is better suited for ranking tasks (i.e., generating top-N recommendations) compared to using a binary cross-entropy loss.\n\n**Key Steps:**\n1. Load and explore the data from `data.csv`\n2. Preprocess the data and map `player_id` and `game_id` to indices\n3. Create a custom PyTorch Dataset that performs pairwise (positive/negative) sampling for BPR loss\n4. Build the NCF model in PyTorch with embedding layers for players and games\n5. Train the model using BPR loss\n6. Extract learned game embeddings and build a FAISS index for fast similarity search\n7. Demonstrate a real-time recommendation query using the FAISS index\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:52.068009Z","iopub.execute_input":"2025-03-06T19:13:52.068384Z","iopub.status.idle":"2025-03-06T19:13:52.078836Z","shell.execute_reply.started":"2025-03-06T19:13:52.068352Z","shell.execute_reply":"2025-03-06T19:13:52.077607Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/slotscsv/data.csv\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:52.080161Z","iopub.execute_input":"2025-03-06T19:13:52.080490Z","iopub.status.idle":"2025-03-06T19:13:56.486225Z","shell.execute_reply.started":"2025-03-06T19:13:52.080434Z","shell.execute_reply":"2025-03-06T19:13:56.484710Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.10.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Cell 1: Import Libraries and Load Data\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nimport faiss\nimport matplotlib.pyplot as plt\n\n# Set random seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nrandom.seed(SEED)\n\n# Load the data from data.csv\ndata = pd.read_csv('/kaggle/input/slotscsv/data.csv')\nprint(\"Data shape:\", data.shape)\ndata.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.488666Z","iopub.execute_input":"2025-03-06T19:13:56.489033Z","iopub.status.idle":"2025-03-06T19:13:56.524280Z","shell.execute_reply.started":"2025-03-06T19:13:56.488999Z","shell.execute_reply":"2025-03-06T19:13:56.522526Z"}},"outputs":[{"name":"stdout","text":"Data shape: (7082, 4)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   player_id  game_id     score  normalized_score\n0          0        0  0.298322          0.050966\n1          0        1  0.465837          0.079584\n2          0        2  0.506277          0.086493\n3          0        3  0.341687          0.058375\n4          0        4  0.667351          0.114012","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player_id</th>\n      <th>game_id</th>\n      <th>score</th>\n      <th>normalized_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.298322</td>\n      <td>0.050966</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.465837</td>\n      <td>0.079584</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0.506277</td>\n      <td>0.086493</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0.341687</td>\n      <td>0.058375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0.667351</td>\n      <td>0.114012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"## Data Exploration and Preprocessing\n\nWe inspect the dataset and encode `player_id` and `game_id` as consecutive integer indices.\n","metadata":{}},{"cell_type":"code","source":"# Cell 2: Data Exploration and Preprocessing\n\n# Explore dataset information\nprint(data.info())\nprint(data.describe())\n\n# Create mapping dictionaries for players and games\nplayer_ids = data['player_id'].unique().tolist()\ngame_ids = data['game_id'].unique().tolist()\n\nplayer2idx = {player: idx for idx, player in enumerate(player_ids)}\ngame2idx = {game: idx for idx, game in enumerate(game_ids)}\n\n# Map original ids to indices\ndata['player_idx'] = data['player_id'].map(player2idx)\ndata['game_idx'] = data['game_id'].map(game2idx)\n\ndata.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.526057Z","iopub.execute_input":"2025-03-06T19:13:56.526548Z","iopub.status.idle":"2025-03-06T19:13:56.571310Z","shell.execute_reply.started":"2025-03-06T19:13:56.526507Z","shell.execute_reply":"2025-03-06T19:13:56.570224Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7082 entries, 0 to 7081\nData columns (total 4 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   player_id         7082 non-null   int64  \n 1   game_id           7082 non-null   int64  \n 2   score             7082 non-null   float64\n 3   normalized_score  7082 non-null   float64\ndtypes: float64(2), int64(2)\nmemory usage: 221.4 KB\nNone\n         player_id      game_id        score  normalized_score\ncount  7082.000000  7082.000000  7082.000000       7082.000000\nmean    253.180175    23.273934     0.364917          0.070602\nstd     143.032060    13.422157     0.169729          0.067376\nmin       0.000000     0.000000     0.005913          0.001235\n25%     129.000000    12.000000     0.239219          0.039379\n50%     254.000000    23.000000     0.347944          0.055885\n75%     377.000000    34.000000     0.471786          0.078073\nmax     499.000000    49.000000     0.976543          1.000000\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   player_id  game_id     score  normalized_score  player_idx  game_idx\n0          0        0  0.298322          0.050966           0         0\n1          0        1  0.465837          0.079584           0         1\n2          0        2  0.506277          0.086493           0         2\n3          0        3  0.341687          0.058375           0         3\n4          0        4  0.667351          0.114012           0         4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player_id</th>\n      <th>game_id</th>\n      <th>score</th>\n      <th>normalized_score</th>\n      <th>player_idx</th>\n      <th>game_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.298322</td>\n      <td>0.050966</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.465837</td>\n      <td>0.079584</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0.506277</td>\n      <td>0.086493</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0.341687</td>\n      <td>0.058375</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0.667351</td>\n      <td>0.114012</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"## Creating a PyTorch Dataset with Pairwise Sampling\n\nFor a ranking-based model, we need to sample negative examples. For each positive interaction (user, game) we randomly sample a negative game that the user has not interacted with. This dataset will return a triplet: (user, positive game, negative game).\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: PyTorch Dataset for Pairwise Ranking (BPR)\n\nclass SlotPairwiseDataset(Dataset):\n    def __init__(self, dataframe, num_games):\n        self.data = dataframe\n        self.num_games = num_games\n        # Create a mapping: user -> set of games the user has interacted with\n        self.user_positive = self.data.groupby('player_idx')['game_idx'].apply(set).to_dict()\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        user = row['player_idx']\n        pos_game = row['game_idx']\n        # Sample a negative game that the user hasn't interacted with\n        positive_set = self.user_positive[user]\n        neg_game = random.randint(0, self.num_games - 1)\n        while neg_game in positive_set:\n            neg_game = random.randint(0, self.num_games - 1)\n        return torch.tensor(user, dtype=torch.long), \\\n               torch.tensor(pos_game, dtype=torch.long), \\\n               torch.tensor(neg_game, dtype=torch.long)\n\nnum_games = len(game2idx)\ndataset = SlotPairwiseDataset(data, num_games)\ndataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=2)\n\n# Display a sample from the dataset\nsample = dataset[0]\nprint(\"Sample (user, positive game, negative game):\", sample)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.572523Z","iopub.execute_input":"2025-03-06T19:13:56.572809Z","iopub.status.idle":"2025-03-06T19:13:56.599764Z","shell.execute_reply.started":"2025-03-06T19:13:56.572782Z","shell.execute_reply":"2025-03-06T19:13:56.598536Z"}},"outputs":[{"name":"stdout","text":"Sample (user, positive game, negative game): (tensor(0), tensor(0), tensor(40))\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## Defining the NCF Model in PyTorch\n\nThe model uses embedding layers for both users and games, concatenates their embeddings, and passes the result through fully connected layers.\n","metadata":{}},{"cell_type":"code","source":"# Cell 4: Define the NCF Model\n\nclass NCFModel(nn.Module):\n    def __init__(self, num_players, num_games, embedding_dim):\n        super(NCFModel, self).__init__()\n        self.player_embedding = nn.Embedding(num_players, embedding_dim)\n        self.game_embedding = nn.Embedding(num_games, embedding_dim)\n        \n        self.fc1 = nn.Linear(embedding_dim * 2, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 32)\n        self.output = nn.Linear(32, 1)\n        self.dropout = nn.Dropout(0.3)\n        \n    def forward(self, user, game):\n        # user and game tensors are of shape (batch, 1) due to unsqueeze in predict_user_scores\n        user_emb = self.player_embedding(user).squeeze(1)  # now shape: (batch, embedding_dim)\n        game_emb = self.game_embedding(game).squeeze(1)      # now shape: (batch, embedding_dim)\n        x = torch.cat([user_emb, game_emb], dim=1)           # shape: (batch, embedding_dim * 2)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))\n        score = self.output(x)\n        return score\n\n\nnum_players = len(player2idx)\nembedding_dim = 32\n\nmodel = NCFModel(num_players, num_games, embedding_dim)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.600829Z","iopub.execute_input":"2025-03-06T19:13:56.601236Z","iopub.status.idle":"2025-03-06T19:13:56.618984Z","shell.execute_reply.started":"2025-03-06T19:13:56.601199Z","shell.execute_reply":"2025-03-06T19:13:56.617835Z"}},"outputs":[{"name":"stdout","text":"NCFModel(\n  (player_embedding): Embedding(500, 32)\n  (game_embedding): Embedding(50, 32)\n  (fc1): Linear(in_features=64, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=32, bias=True)\n  (output): Linear(in_features=32, out_features=1, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Defining the BPR Loss Function\n\nWe implement Bayesian Personalized Ranking (BPR) loss. For each triplet (user, positive, negative), the loss encourages the score of the positive item to be higher than the negative.\n","metadata":{}},{"cell_type":"code","source":"# Cell 5: BPR Loss Function\n\ndef bpr_loss(pos_scores, neg_scores):\n    # Loss = -log(sigmoid(pos - neg))\n    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n    return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.621862Z","iopub.execute_input":"2025-03-06T19:13:56.622155Z","iopub.status.idle":"2025-03-06T19:13:56.653512Z","shell.execute_reply.started":"2025-03-06T19:13:56.622130Z","shell.execute_reply":"2025-03-06T19:13:56.652543Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## Training with Validation and Early Stopping\n\nTo monitor our model's performance and prevent overfitting, we now split our dataset into training and validation sets (80% training, 20% validation). We will track the validation loss at the end of each epoch and use early stopping—halting training if the validation loss does not improve for a specified number of epochs (patience). This approach ensures that our model generalizes well to unseen data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset\n\n# Split the indices for training (80%) and validation (20%)\nall_indices = np.arange(len(dataset))\ntrain_indices, val_indices = train_test_split(all_indices, test_size=0.2, random_state=SEED)\n\n# Create subset datasets for training and validation\ntrain_subset = Subset(dataset, train_indices)\nval_subset = Subset(dataset, val_indices)\n\n# Create DataLoaders for training and validation\ntrain_loader = DataLoader(train_subset, batch_size=256, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_subset, batch_size=256, shuffle=False, num_workers=2)\n\nprint(\"Training samples:\", len(train_subset))\nprint(\"Validation samples:\", len(val_subset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.654828Z","iopub.execute_input":"2025-03-06T19:13:56.655119Z","iopub.status.idle":"2025-03-06T19:13:56.680565Z","shell.execute_reply.started":"2025-03-06T19:13:56.655094Z","shell.execute_reply":"2025-03-06T19:13:56.679437Z"}},"outputs":[{"name":"stdout","text":"Training samples: 5665\nValidation samples: 1417\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Early stopping parameters\nbest_val_loss = float('inf')\npatience = 5  # Number of epochs to wait for improvement before stopping\nepochs_without_improvement = 0\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nnum_epochs = 40\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    for user, pos_game, neg_game in train_loader:\n        optimizer.zero_grad()\n        pos_score = model(user, pos_game).squeeze()\n        neg_score = model(user, neg_game).squeeze()\n        loss = bpr_loss(pos_score, neg_score)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * user.size(0)\n    train_loss /= len(train_subset)\n    \n    # Evaluate on the validation set\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for user, pos_game, neg_game in val_loader:\n            pos_score = model(user, pos_game).squeeze()\n            neg_score = model(user, neg_game).squeeze()\n            loss = bpr_loss(pos_score, neg_score)\n            val_loss += loss.item() * user.size(0)\n    val_loss /= len(val_subset)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n    \n    # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_without_improvement = 0\n        # Optionally, save the model state here:\n        # torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        epochs_without_improvement += 1\n    \n    if epochs_without_improvement >= patience:\n        print(\"Early stopping triggered!\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:13:56.681742Z","iopub.execute_input":"2025-03-06T19:13:56.682156Z","iopub.status.idle":"2025-03-06T19:14:33.773690Z","shell.execute_reply.started":"2025-03-06T19:13:56.682114Z","shell.execute_reply":"2025-03-06T19:14:33.772437Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/40, Train Loss: 0.6899, Val Loss: 0.6834\nEpoch 2/40, Train Loss: 0.6705, Val Loss: 0.6630\nEpoch 3/40, Train Loss: 0.6535, Val Loss: 0.6486\nEpoch 4/40, Train Loss: 0.6486, Val Loss: 0.6316\nEpoch 5/40, Train Loss: 0.6375, Val Loss: 0.6348\nEpoch 6/40, Train Loss: 0.6376, Val Loss: 0.6377\nEpoch 7/40, Train Loss: 0.6292, Val Loss: 0.6315\nEpoch 8/40, Train Loss: 0.6265, Val Loss: 0.6312\nEpoch 9/40, Train Loss: 0.6197, Val Loss: 0.6270\nEpoch 10/40, Train Loss: 0.6177, Val Loss: 0.6284\nEpoch 11/40, Train Loss: 0.6105, Val Loss: 0.6195\nEpoch 12/40, Train Loss: 0.6147, Val Loss: 0.6260\nEpoch 13/40, Train Loss: 0.6071, Val Loss: 0.6123\nEpoch 14/40, Train Loss: 0.5938, Val Loss: 0.6218\nEpoch 15/40, Train Loss: 0.5990, Val Loss: 0.6287\nEpoch 16/40, Train Loss: 0.5925, Val Loss: 0.6065\nEpoch 17/40, Train Loss: 0.5871, Val Loss: 0.6201\nEpoch 18/40, Train Loss: 0.5753, Val Loss: 0.6121\nEpoch 19/40, Train Loss: 0.5824, Val Loss: 0.6027\nEpoch 20/40, Train Loss: 0.5709, Val Loss: 0.6082\nEpoch 21/40, Train Loss: 0.5735, Val Loss: 0.6114\nEpoch 22/40, Train Loss: 0.5718, Val Loss: 0.6041\nEpoch 23/40, Train Loss: 0.5617, Val Loss: 0.5908\nEpoch 24/40, Train Loss: 0.5425, Val Loss: 0.5878\nEpoch 25/40, Train Loss: 0.5496, Val Loss: 0.5862\nEpoch 26/40, Train Loss: 0.5383, Val Loss: 0.5979\nEpoch 27/40, Train Loss: 0.5346, Val Loss: 0.5820\nEpoch 28/40, Train Loss: 0.5224, Val Loss: 0.5970\nEpoch 29/40, Train Loss: 0.5125, Val Loss: 0.5791\nEpoch 30/40, Train Loss: 0.5156, Val Loss: 0.5718\nEpoch 31/40, Train Loss: 0.5134, Val Loss: 0.5770\nEpoch 32/40, Train Loss: 0.4960, Val Loss: 0.5820\nEpoch 33/40, Train Loss: 0.4949, Val Loss: 0.5779\nEpoch 34/40, Train Loss: 0.4877, Val Loss: 0.5675\nEpoch 35/40, Train Loss: 0.4852, Val Loss: 0.5750\nEpoch 36/40, Train Loss: 0.4818, Val Loss: 0.5764\nEpoch 37/40, Train Loss: 0.4644, Val Loss: 0.5478\nEpoch 38/40, Train Loss: 0.4711, Val Loss: 0.5572\nEpoch 39/40, Train Loss: 0.4644, Val Loss: 0.5429\nEpoch 40/40, Train Loss: 0.4676, Val Loss: 0.5641\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## Extracting Game Embeddings\n\nOnce the model is trained, we extract the learned game (slot) embeddings. These embeddings will be used to build the FAISS index for fast similarity queries.\n","metadata":{}},{"cell_type":"code","source":"# Cell 7: Extract Game Embeddings\n\nmodel.eval()\nwith torch.no_grad():\n    # Get the game embeddings from the model\n    game_embeddings = model.game_embedding.weight.detach().cpu().numpy()\nprint(\"Game Embeddings Shape:\", game_embeddings.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.775084Z","iopub.execute_input":"2025-03-06T19:14:33.775541Z","iopub.status.idle":"2025-03-06T19:14:33.782689Z","shell.execute_reply.started":"2025-03-06T19:14:33.775480Z","shell.execute_reply":"2025-03-06T19:14:33.781665Z"}},"outputs":[{"name":"stdout","text":"Game Embeddings Shape: (50, 32)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## Building the FAISS Index\n\nWe use FAISS to index the game embeddings. This will enable fast Approximate Nearest Neighbors (ANN) search in real time.\n","metadata":{}},{"cell_type":"code","source":"# Cell 8: Build FAISS Index\n\n# Ensure embeddings are float32\ngame_embeddings = game_embeddings.astype('float32')\n\n# Create a FAISS index using L2 distance\nfaiss_index = faiss.IndexFlatL2(embedding_dim)\nfaiss_index.add(game_embeddings)\n\nprint(\"FAISS index built with {} vectors.\".format(faiss_index.ntotal))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.783665Z","iopub.execute_input":"2025-03-06T19:14:33.784047Z","iopub.status.idle":"2025-03-06T19:14:33.811419Z","shell.execute_reply.started":"2025-03-06T19:14:33.784010Z","shell.execute_reply":"2025-03-06T19:14:33.810334Z"}},"outputs":[{"name":"stdout","text":"FAISS index built with 50 vectors.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## Advanced Recommendation Functions for Production\n\nIn this section, we provide several utility functions that demonstrate the full potential of our recommendation system. These functions include both offline (batch) recommendations and real‑time recommendations using our FAISS index.\n\nBefore using these functions, ensure the following global variables are defined:\n- **model**: The trained NCF model (set to evaluation mode when using the functions).\n- **game_embeddings**: A NumPy array of game (slot) embeddings extracted from the model.\n- **faiss_index**: A FAISS index built on `game_embeddings` (using L2 distance).\n- **num_games**: Total number of games in the system.\n- **user_positive**: A dictionary mapping each user (player_idx) to a set of game indices that the user has already interacted with.  \n  For example, you can create it with:\n  ```python\n  user_positive = data.groupby('player_idx')['game_idx'].apply(set).to_dict()\n","metadata":{}},{"cell_type":"code","source":"# Cell: Offline Recommendation Utility Functions\n\ndef predict_user_scores(user_id, candidate_games):\n    \"\"\"\n    Predict scores for a given user over a set of candidate games using the NCF model.\n    \n    Args:\n        user_id (int): Index (ID) of the user.\n        candidate_games (list or np.array): List of candidate game indices.\n    \n    Returns:\n        np.array: Predicted scores for each candidate game.\n    \"\"\"\n    model.eval()\n    with torch.no_grad():\n        user_tensor = torch.tensor([user_id] * len(candidate_games), dtype=torch.long).unsqueeze(1)\n        game_tensor = torch.tensor(candidate_games, dtype=torch.long).unsqueeze(1)\n        predictions = model(user_tensor, game_tensor).squeeze().cpu().numpy()\n    return predictions\n\n\ndef recommend_slots_for_user(user_id, k=5):\n    \"\"\"\n    Recommend the top-k slots for a user based solely on model-predicted scores.\n    \n    The function excludes games the user has already interacted with and then\n    ranks the remaining candidate games based on predicted preference.\n    \n    Args:\n        user_id (int): Index (ID) of the user.\n        k (int): Number of recommendations to return.\n    \n    Returns:\n        recommended_games (np.array): Indices of recommended games.\n        predicted_scores (np.array): Predicted scores for these games.\n    \"\"\"\n    interacted_games = user_positive.get(user_id, set())\n    candidate_games = [game for game in range(num_games) if game not in interacted_games]\n    \n    if not candidate_games:\n        print(f\"User {user_id} has interacted with all games. No recommendations available.\")\n        return np.array([]), np.array([])\n    \n    scores = predict_user_scores(user_id, candidate_games)\n    top_indices = np.argsort(scores)[-k:][::-1]\n    recommended_games = np.array(candidate_games)[top_indices]\n    predicted_scores = scores[top_indices]\n    return recommended_games, predicted_scores\n\n\ndef cosine_similarity_matrix(query_embedding, candidate_embeddings):\n    \"\"\"\n    Compute cosine similarity between a query embedding and a set of candidate embeddings.\n    \n    Args:\n        query_embedding (np.array): Query vector of shape (embedding_dim,).\n        candidate_embeddings (np.array): Candidate embeddings of shape (num_candidates, embedding_dim).\n    \n    Returns:\n        np.array: Cosine similarity scores scaled to the range [0, 1].\n    \"\"\"\n    query_norm = query_embedding / np.linalg.norm(query_embedding)\n    candidate_norms = candidate_embeddings / np.linalg.norm(candidate_embeddings, axis=1, keepdims=True)\n    cos_sim = np.dot(candidate_norms, query_norm)\n    cos_sim = (cos_sim + 1) / 2  # Scale from [-1, 1] to [0, 1]\n    return cos_sim\n\n\ndef recommend_slots_for_user_based_on_recent_slot(user_id, recent_slot_id, k=5, alpha=0.5):\n    \"\"\"\n    Recommend top-k slots for a user by combining the NCF model's predicted scores and the cosine\n    similarity of candidate slots to a recently played slot.\n    \n    The final combined score is computed as:\n        combined_score = alpha * (predicted score) + (1 - alpha) * (similarity score)\n    \n    Args:\n        user_id (int): Index (ID) of the user.\n        recent_slot_id (int): Index (ID) of the slot recently played by the user.\n        k (int): Number of recommendations to return.\n        alpha (float): Weight balancing the predicted score and similarity score.\n    \n    Returns:\n        recommended_games (np.array): Indices of recommended games.\n        combined_scores (np.array): Final combined scores used for ranking.\n    \"\"\"\n    interacted_games = user_positive.get(user_id, set())\n    candidate_games = [game for game in range(num_games) if game not in interacted_games]\n    \n    if not candidate_games:\n        print(f\"User {user_id} has interacted with all games. No recommendations available.\")\n        return np.array([]), np.array([])\n    \n    predicted_scores = predict_user_scores(user_id, candidate_games)\n    recent_embedding = game_embeddings[recent_slot_id]\n    candidate_embeddings = game_embeddings[candidate_games]\n    similarity_scores = cosine_similarity_matrix(recent_embedding, candidate_embeddings)\n    combined_scores = alpha * predicted_scores + (1 - alpha) * similarity_scores\n    \n    top_indices = np.argsort(combined_scores)[-k:][::-1]\n    recommended_games = np.array(candidate_games)[top_indices]\n    top_combined_scores = combined_scores[top_indices]\n    return recommended_games, top_combined_scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.812741Z","iopub.execute_input":"2025-03-06T19:14:33.813175Z","iopub.status.idle":"2025-03-06T19:14:33.840775Z","shell.execute_reply.started":"2025-03-06T19:14:33.813119Z","shell.execute_reply":"2025-03-06T19:14:33.839664Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"## Real-Time Recommendation Functions\n\nFor real‑time recommendations, speed is critical. Using our pre-built FAISS index, we can quickly retrieve the nearest neighbor slots for a given slot (e.g., one recently played by the user). We then filter the results based on the user's history.\n\nBelow is a real‑time recommendation function that:\n1. Uses the FAISS index to quickly find similar slots to a given (recently played) slot.\n2. Filters out slots that the user has already interacted with.\n3. Returns the top-k most similar slots for immediate serving.\n","metadata":{}},{"cell_type":"code","source":"def realtime_recommendation_for_recent_slot(user_id, recent_slot_id, k=5, search_k=10):\n    \"\"\"\n    Generate real-time recommendations for a user based on a recently played slot,\n    using the FAISS index.\n    \n    Args:\n        user_id (int): Index (ID) of the user.\n        recent_slot_id (int): Index (ID) of the slot recently played.\n        k (int): Number of recommendations to return.\n        search_k (int): Number of nearest neighbors to retrieve from FAISS before filtering.\n    \n    Returns:\n        recommended_games (np.array): Indices of recommended games.\n        distances (np.array): L2 distances corresponding to the recommended games.\n    \"\"\"\n    # Retrieve the query embedding from the recent slot.\n    query_vector = np.expand_dims(game_embeddings[recent_slot_id], axis=0)\n    \n    # Use FAISS to search for the nearest neighbors.\n    distances, indices = faiss_index.search(query_vector, search_k)\n    candidate_games = indices[0]\n    candidate_distances = distances[0]\n    \n    # Filter out games already interacted with by the user.\n    interacted_games = user_positive.get(user_id, set())\n    filtered = []\n    for game, dist in zip(candidate_games, candidate_distances):\n        if game not in interacted_games and game != recent_slot_id:\n            filtered.append((game, dist))\n        if len(filtered) == k:\n            break\n    \n    if not filtered:\n        print(f\"No new recommendations available for user {user_id} in real-time.\")\n        return np.array([]), np.array([])\n    \n    # Return filtered recommendations.\n    recommended_games = np.array([item[0] for item in filtered])\n    distances_out = np.array([item[1] for item in filtered])\n    return recommended_games, distances_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.842003Z","iopub.execute_input":"2025-03-06T19:14:33.842402Z","iopub.status.idle":"2025-03-06T19:14:33.868756Z","shell.execute_reply.started":"2025-03-06T19:14:33.842360Z","shell.execute_reply":"2025-03-06T19:14:33.867605Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"## Demonstration of the Functions\n\nLet's see how these functions work for a sample user. We demonstrate:\n1. **Offline Recommendation (Model-Only):** Top‑5 recommendations based on predicted scores.\n2. **Offline Hybrid Recommendation:** Combining model predictions with similarity to a recently played slot.\n3. **Real-Time Recommendation:** Using the FAISS index for quick recommendations based on the recent slot.\n","metadata":{}},{"cell_type":"code","source":"# Create the user_positive mapping from the dataset\nuser_positive = data.groupby('player_idx')['game_idx'].apply(set).to_dict()\n\n# Verify the mapping by printing a sample entry\nprint(\"Sample user_positive mapping:\")\nprint({k: user_positive[k] for k in list(user_positive.keys())[:3]})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.870056Z","iopub.execute_input":"2025-03-06T19:14:33.870448Z","iopub.status.idle":"2025-03-06T19:14:33.907531Z","shell.execute_reply.started":"2025-03-06T19:14:33.870417Z","shell.execute_reply":"2025-03-06T19:14:33.906614Z"}},"outputs":[{"name":"stdout","text":"Sample user_positive mapping:\n{0: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}, 1: {1, 2, 6, 7, 8, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28}, 2: {4, 5, 9, 14, 16, 19, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Sample parameters for demonstration\nsample_user_id = 0\nsample_recent_slot_id = 0  # Assume user 0 recently played slot with index 0\n\n# 1. Offline recommendation using predicted scores.\noffline_recs, offline_scores = recommend_slots_for_user(sample_user_id, k=5)\nprint(\"Offline Recommendations (Model-Only):\")\nprint(\"Slot Indices:\", offline_recs)\nprint(\"Predicted Scores:\", offline_scores)\n\n# 2. Offline hybrid recommendation (model predictions + recent slot similarity).\nhybrid_recs, hybrid_scores = recommend_slots_for_user_based_on_recent_slot(sample_user_id, sample_recent_slot_id, k=5, alpha=0.5)\nprint(\"\\nOffline Hybrid Recommendations (User based on recent slot):\")\nprint(\"Slot Indices:\", hybrid_recs)\nprint(\"Combined Scores:\", hybrid_scores)\n\n# 3. Real-Time recommendation using the FAISS index.\nrealtime_recs, realtime_dists = realtime_recommendation_for_recent_slot(sample_user_id, sample_recent_slot_id, k=5, search_k=10)\nprint(\"\\nReal-Time Recommendations (using FAISS):\")\nprint(\"Slot Indices:\", realtime_recs)\nprint(\"L2 Distances:\", realtime_dists)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.908446Z","iopub.execute_input":"2025-03-06T19:14:33.908788Z","iopub.status.idle":"2025-03-06T19:14:33.923125Z","shell.execute_reply.started":"2025-03-06T19:14:33.908761Z","shell.execute_reply":"2025-03-06T19:14:33.922141Z"}},"outputs":[{"name":"stdout","text":"Offline Recommendations (Model-Only):\nSlot Indices: [24 35 16 29 48]\nPredicted Scores: [1.2998497  1.1528544  1.0116501  0.78076214 0.5764941 ]\n\nOffline Hybrid Recommendations (User based on recent slot):\nSlot Indices: [24 35 16 29 48]\nCombined Scores: [0.980188   0.79492486 0.7249991  0.65784085 0.58863205]\n\nReal-Time Recommendations (using FAISS):\nSlot Indices: [22 19 43 48 17]\nL2 Distances: [37.157726 38.085705 46.559784 46.572144 47.28547 ]\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## Explanation of Updated Evaluation Results\n\nBelow are the latest outputs from our recommendation functions. Let’s break down what these numbers mean in the context of our online casino recommendation system.\n\n### Offline Recommendations (Model-Only)\n- **Slot Indices:** `[24, 35, 16, 29, 48]`\n- **Predicted Scores:** `[1.2998497, 1.1528544, 1.0116501, 0.78076214, 0.5764941]`\n\n**Interpretation:**\n- These recommendations are generated solely by the model using learned user–slot interactions.\n- The predicted scores represent the model’s confidence in the user’s potential interest in each slot. For instance, slot 24 has the highest predicted score (~1.30), suggesting it’s the most likely candidate for the user.\n- The ordering reflects relative preference; slots with higher scores (e.g., 24 and 35) are predicted to be more appealing compared to those with lower scores.\n\n---\n\n### Offline Hybrid Recommendations (User Based on Recent Slot)\n- **Slot Indices:** `[24, 35, 16, 29, 48]`\n- **Combined Scores:** `[0.980188, 0.79492486, 0.7249991, 0.65784085, 0.58863205]`\n\n**Interpretation:**\n- The hybrid method combines the model’s predicted scores with a cosine similarity measure between candidate slots and a recently played slot.\n- In this case, the ordering remains the same as the model-only recommendations. However, the combined scores are scaled down compared to the predicted scores because the similarity component (weighted in the combination) typically ranges between 0 and 1.\n- This method provides a more nuanced recommendation that takes into account both the overall user preference and the immediate context of recent activity, reinforcing slots like 24 as top recommendations.\n\n---\n\n### Real-Time Recommendations (Using FAISS)\n- **Slot Indices:** `[22, 19, 43, 48, 17]`\n- **L2 Distances:** `[37.157726, 38.085705, 46.559784, 46.572144, 47.28547]`\n\n**Interpretation:**\n- Real-time recommendations are derived using the FAISS index to quickly locate slots that are closest in the embedding space to a recently played slot.\n- Here, the L2 distances indicate the similarity in terms of the learned slot representations: lower distances imply higher similarity.\n- Slot 22, with the smallest distance (~37.16), is the closest match to the recent slot, even though it wasn’t selected in the offline (model-only or hybrid) recommendations. This indicates that while the model-based methods prioritize the user's overall long-term preferences, the FAISS-based real-time approach emphasizes immediate similarity.\n- The difference in recommended indices between the offline and real-time methods shows that different strategies capture different aspects of user behavior (global preferences vs. immediate context).\n\n---\n\n### Overall Summary:\n- **Consistency Across Methods:**  \n  Notice that slot 48 appears in both offline approaches, suggesting it is consistently relevant according to the model. However, the real-time approach introduces new candidates (e.g., slot 22) based on embedding similarity.\n- **Score vs. Distance:**  \n  The offline methods return predicted or combined scores that quantify expected user interest, while the real-time method provides L2 distances indicating embedding similarity.\n- **Practical Impact:**  \n  These results demonstrate the complementary nature of different recommendation strategies. The model-only and hybrid methods help capture overall user preferences, whereas the FAISS-based real-time recommendations offer fast, context-aware suggestions.\n\nIn summary, your updated results are in line with expectations and illustrate how different aspects of the recommendation pipeline work together to deliver personalized slot suggestions.\n","metadata":{}},{"cell_type":"markdown","source":"## Model Evaluation\n\nTo ensure our recommendation system effectively captures user preferences and ranks relevant slots appropriately, we must evaluate its performance using offline metrics. In this section, we use a hold-out test set to measure the quality of our recommendations with the following key metrics:\n\n- **Hit Rate (HR@K):**  \n  This metric measures the proportion of users for whom at least one relevant (held-out) item appears in the top‑K recommendations. A higher hit rate indicates that the model frequently includes a relevant slot in its recommendations.\n\n- **Normalized Discounted Cumulative Gain (NDCG@K):**  \n  NDCG@K assesses the ranking quality by giving higher scores when relevant items appear near the top of the recommendation list. This metric considers the position of the relevant items, providing a more nuanced evaluation of the model's performance.\n\nBy creating a test set from held-out user interactions (e.g., the most recent interactions for each user), we simulate a real-world scenario where the model's predictions are compared against actual user behavior. This evaluation process is crucial for:\n- Validating the effectiveness of our training approach and model architecture.\n- Guiding further improvements and hyperparameter tuning.\n- Establishing a performance baseline for future A/B testing before deployment.\n\nLet's now evaluate our model using these metrics.\n","metadata":{}},{"cell_type":"code","source":"def hit_rate_at_k(recommended_items, ground_truth):\n    \"\"\"\n    Compute Hit Rate at K.\n    \n    Args:\n        recommended_items (list or np.array): Recommended item indices.\n        ground_truth (set): Set of ground-truth item indices.\n    \n    Returns:\n        int: 1 if at least one ground-truth item is in recommended_items, else 0.\n    \"\"\"\n    return int(len(set(recommended_items) & ground_truth) > 0)\n\ndef ndcg_at_k(recommended_items, ground_truth, k):\n    \"\"\"\n    Compute NDCG at K for a single user.\n    \n    Args:\n        recommended_items (list or np.array): Recommended item indices (ordered by rank).\n        ground_truth (set): Set of ground-truth item indices.\n        k (int): Rank cutoff.\n    \n    Returns:\n        float: NDCG score.\n    \"\"\"\n    dcg = 0.0\n    for i, item in enumerate(recommended_items[:k]):\n        if item in ground_truth:\n            dcg += 1 / np.log2(i + 2)  # i+2 because log2(1) = 0, so rank 1 is log2(2)\n    \n    # Ideal DCG: all relevant items ranked at the top\n    ideal_rels = min(len(ground_truth), k)\n    idcg = sum([1 / np.log2(i + 2) for i in range(ideal_rels)])\n    \n    return dcg / idcg if idcg > 0 else 0.0\n\ndef evaluate_model(test_interactions, k=5):\n    \"\"\"\n    Evaluate the recommendation model using Hit Rate and NDCG metrics.\n    \n    Args:\n        test_interactions (dict): Mapping from user_id to a set of held-out (ground-truth) game indices.\n        k (int): Top-K recommendations to consider.\n    \n    Returns:\n        metrics (dict): Dictionary with average Hit Rate and NDCG.\n    \"\"\"\n    hit_rates = []\n    ndcgs = []\n    # Evaluate over each user in the test set\n    for user_id, ground_truth in test_interactions.items():\n        # Generate recommendations for the user using the offline recommendation function.\n        recommended_games, _ = recommend_slots_for_user(user_id, k=k)\n        hr = hit_rate_at_k(recommended_games, ground_truth)\n        ndcg = ndcg_at_k(recommended_games, ground_truth, k)\n        hit_rates.append(hr)\n        ndcgs.append(ndcg)\n    \n    avg_hr = np.mean(hit_rates)\n    avg_ndcg = np.mean(ndcgs)\n    return {'Hit Rate@{}'.format(k): avg_hr, 'NDCG@{}'.format(k): avg_ndcg}\n\n# Example: Suppose we have a test_interactions dictionary created from our hold-out set.\n# For demonstration, let's create a dummy test set.\n# In practice, test_interactions should be created by holding out recent interactions per user.\ntest_interactions = {\n    0: {2, 5},   # For user 0, the held-out items are game 2 and game 5.\n    1: {7},      # For user 1, the held-out item is game 7.\n    2: {3, 8}    # And so on...\n}\n\n# Evaluate the model for top-5 recommendations.\nevaluation_metrics = evaluate_model(test_interactions, k=5)\nprint(\"Evaluation Metrics:\")\nprint(evaluation_metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T19:14:33.924176Z","iopub.execute_input":"2025-03-06T19:14:33.924582Z","iopub.status.idle":"2025-03-06T19:14:33.956441Z","shell.execute_reply.started":"2025-03-06T19:14:33.924527Z","shell.execute_reply":"2025-03-06T19:14:33.955341Z"}},"outputs":[{"name":"stdout","text":"Evaluation Metrics:\n{'Hit Rate@5': 0.0, 'NDCG@5': 0.0}\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"## Production Pipeline Summary\n\nTo ensure that our recommendation system delivers the best results in production, the company should follow this pipeline:\n\n1. **Data Collection & Preprocessing:**  \n   - Continuously collect user interactions, including play durations, frequency, and other engagement metrics.\n   - Preprocess the data by mapping user and game IDs to indices and compute interaction scores.  \n   - Optionally, integrate multiple signals (e.g., recency, monetary value) to refine the implicit feedback.\n\n2. **Model Training & Embedding Extraction:**  \n   - Retrain the Neural Collaborative Filtering (NCF) model periodically (e.g., daily) using the latest data.\n   - Use a ranking-based loss (e.g., BPR) to directly optimize for the top‑n recommendation task.\n   - Extract and store fresh player and game embeddings after each training cycle.\n\n3. **Indexing & Real-Time Serving:**  \n   - Build a FAISS index from the game embeddings to allow for lightning‑fast nearest neighbor searches.\n   - Update the index regularly in sync with model retraining.\n   - Use the FAISS‑based real‑time functions to quickly retrieve similar games based on a user’s recent activity.\n\n4. **Offline & Hybrid Recommendation Generation:**  \n   - Generate batch recommendations using offline functions that filter out already interacted games.\n   - Combine predicted user preferences with similarity signals (e.g., recent slot similarity) to enhance personalization.\n\n5. **Monitoring, Evaluation & Feedback Loop:**  \n   - Continuously monitor key performance indicators (e.g., engagement rate, click‑through rate).\n   - Perform A/B tests to validate new recommendation strategies.\n   - Use feedback to adjust model parameters, sampling strategies, and the overall recommendation logic.\n\n6. **Deployment & Maintenance:**  \n   - Refactor the notebook code into modular, production‑ready services (e.g., microservices).\n   - Implement automated retraining and index update pipelines.\n   - Ensure robust logging, error handling, and scalability to handle high user traffic.\n\nBy following this pipeline, the company can maintain a state‑of‑the‑art recommendation system that is both highly personalized and efficient, ensuring maximum engagement and a superior user experience.","metadata":{}}]}