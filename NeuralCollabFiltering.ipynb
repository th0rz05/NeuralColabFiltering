{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id  game_id     score\n",
      "0          0        0  0.298322\n",
      "1          0        1  0.465837\n",
      "2          0        2  0.506277\n",
      "3          0        3  0.341687\n",
      "4          0        4  0.667351\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.width', 1000)  # Change 1000 to the desired width\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"slot_game_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "df[['session_duration_hours', 'money_spent', 'avg_bet_amount']] = scaler.fit_transform(df[['session_duration_hours', 'money_spent', 'avg_bet_amount']])\n",
    "\n",
    "# Define weights (you can adjust these based on domain knowledge)\n",
    "weights = {\n",
    "    'session_duration_hours': 0.4,\n",
    "    'money_spent': 0.4,\n",
    "    'avg_bet_amount': 0.2\n",
    "}\n",
    "\n",
    "# Calculate the score\n",
    "df['score'] = (df['session_duration_hours'] * weights['session_duration_hours'] +\n",
    "               df['money_spent'] * weights['money_spent'] +\n",
    "               df['avg_bet_amount'] * weights['avg_bet_amount'])\n",
    "\n",
    "# Aggregate scores by player_id and game_id (e.g., using mean)\n",
    "df = df.groupby(['player_id', 'game_id'])['score'].mean().reset_index()\n",
    "\n",
    "# Create a mapping of unique player and game IDs to indices\n",
    "player_mapping = {player: idx for idx, player in enumerate(df['player_id'].unique())}\n",
    "game_mapping = {game: idx for idx, game in enumerate(df['game_id'].unique())}\n",
    "\n",
    "df['player_id'] = df['player_id'].map(player_mapping)\n",
    "df['game_id'] = df['game_id'].map(game_mapping)\n",
    "\n",
    "# Check if the aggregation was successful\n",
    "print(df.head())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFM(nn.Module):\n",
    "    def __init__(self, num_users, num_games, embedding_dim=50, hidden_layers=[128, 64]):\n",
    "        super(NFM, self).__init__()\n",
    "        \n",
    "        # User and Game embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.game_embedding = nn.Embedding(num_games, embedding_dim)\n",
    "        \n",
    "        # MLP layers (hidden layers)\n",
    "        layers = []\n",
    "        in_size = embedding_dim * 3  # user + game + interaction term\n",
    "        for out_size in hidden_layers:\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            in_size = out_size\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # Output layer (single output)\n",
    "        self.output = nn.Linear(hidden_layers[-1], 1)\n",
    "        \n",
    "        # Bias terms for user and game\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.game_bias = nn.Embedding(num_games, 1)\n",
    "\n",
    "    def forward(self, user, game):\n",
    "        # Get embeddings\n",
    "        user_emb = self.user_embedding(user)\n",
    "        game_emb = self.game_embedding(game)\n",
    "        \n",
    "        # Interaction term (FM part): pairwise interaction between user and game\n",
    "        interaction = user_emb * game_emb  # element-wise multiplication\n",
    "        \n",
    "        # Concatenate user, game, and interaction features\n",
    "        x = torch.cat([user_emb, game_emb, interaction], dim=1)\n",
    "        \n",
    "        # Pass through MLP layers\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        # Output prediction\n",
    "        x = self.output(x)\n",
    "        \n",
    "        # Add biases for user and game, but now we will properly broadcast them\n",
    "        user_b = self.user_bias(user).squeeze()  # Shape [batch_size, 1] to [batch_size]\n",
    "        game_b = self.game_bias(game).squeeze()  # Shape [batch_size, 1] to [batch_size]\n",
    "        \n",
    "        # Add the bias terms\n",
    "        x += user_b + game_b\n",
    "        \n",
    "        return x.squeeze()  # Output shape: [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Predict Scores for a Batch of Games\n",
    "def predict_scores_batch(user_id, games, model, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Predict engagement scores for a given user and list of games in batches.\n",
    "    \"\"\"\n",
    "    user_tensor = torch.tensor([user_id] * len(games), dtype=torch.long).to(device)\n",
    "    game_tensor = torch.tensor(games, dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, game_tensor)\n",
    "    \n",
    "    scores = predictions.cpu().numpy().flatten()\n",
    "    return dict(zip(games, scores))\n",
    "\n",
    "# Function to Recommend Top-N Games\n",
    "def recommend_top_n(user_id, games, model, df, n=5, recommend_new_only=True, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Recommend the top-N slot games for a single user.\n",
    "    \"\"\"\n",
    "    if recommend_new_only:\n",
    "        # Optimize: Only consider unplayed games\n",
    "        played_games = set(df[df['player_id'] == user_id]['game_id'].unique())\n",
    "        games_to_recommend = [game_id for game_id in games if game_id not in played_games]\n",
    "    else:\n",
    "        # Consider both played and unplayed games\n",
    "        games_to_recommend = games\n",
    "    \n",
    "    # Predict scores for the selected games in a batch\n",
    "    scores = predict_scores_batch(user_id, games_to_recommend, model, device)\n",
    "    \n",
    "    # Sort games based on predicted scores\n",
    "    sorted_games = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top-N recommended game IDs\n",
    "    return [game_id for game_id, _ in sorted_games[:n]]\n",
    "\n",
    "# Get all game IDs\n",
    "all_game_ids = df[\"game_id\"].unique().tolist()\n",
    "\n",
    "# Test for an existing user\n",
    "existing_user_id = 123  # Change to an actual user ID\n",
    "\n",
    "# Option 1: Recommend only new slots\n",
    "print(\"Recommendations for new slots only:\", recommend_top_n(existing_user_id, all_game_ids, model, df, recommend_new_only=True))\n",
    "\n",
    "# Option 2: Recommend all slots (including played ones)\n",
    "print(\"Recommendations for all slots:\", recommend_top_n(existing_user_id, all_game_ids, model, df, recommend_new_only=False))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
